{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hterborg/.local/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "#%load_ext tensorboard\n",
    "\n",
    "#import datetime\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "#import matplotlib as plt\n",
    "\n",
    "import os\n",
    "\n",
    "#added\n",
    "import h5py\n",
    "\n",
    "#import tensorflow as tf\n",
    "\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "#tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:86:00.0, compute capability: 7.0\n",
      "\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, 974782997815470631),\n",
       " _DeviceAttributes(/job:localhost/replica:0/task:0/device:GPU:0, GPU, 31592420480, 7121197767071902605)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True)) #check if gpu is used\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "  devices = sess.list_devices()\n",
    "devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vols = h5py.File(\"/scratch/hterborg/brute_force/Thesis/zero_3_runs_15_train_1_test_dataset.mat\",'r')\n",
    "                 \n",
    "                 \n",
    "                 #15train_onetest_dataset.mat\",'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_x', 'test_y', 'testsubject', 'train_x', 'train_y', 'trainsubjects']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vols\n",
    "\n",
    "list(vols.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = vols['train_x'], vols['train_y'], vols['test_x'], vols['test_y']\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2745103850"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.size(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.transpose(X_train)\n",
    "y_train=np.transpose(y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=np.transpose(X_test)\n",
    "y_test=np.transpose(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4630, 79, 95, 79) (4630, 1)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train),np.shape(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = X_train[:1000,:,:,:]\n",
    "#y_train = y_train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 16.]]\n"
     ]
    }
   ],
   "source": [
    "trainsubjects = np.transpose(vols['trainsubjects'])\n",
    "print(trainsubjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4630, 79, 95, 79) (4630, 1)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train),np.shape(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### z-scoring to normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = np.mean(X_train)\n",
    "x_std = np.std(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_centered = (X_train - x_mean)/x_std\n",
    "X_ts_centered = (X_test - x_mean)/x_std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D array for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.flatten()\n",
    "y_test = y_test.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking out the dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4630, 79, 95, 79), (316, 79, 95, 79), (4630,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr_centered.shape,  X_ts_centered.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999993"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(X_tr_centered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking out the image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch generator: to generate mini-batches for training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size=50, \n",
    "                    shuffle=True, random_seed=None):\n",
    "    \n",
    "    idx = np.arange(y.shape[0])\n",
    "    \n",
    "    if shuffle:\n",
    "        rng = np.random.RandomState(random_seed)\n",
    "        rng.shuffle(idx)\n",
    "        X = X[idx]\n",
    "        y = y[idx]\n",
    "    \n",
    "    for i in range(0, X.shape[0], batch_size):\n",
    "        #print(i)\n",
    "        yield (X[i:i+batch_size, :], y[i:i+batch_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D-CNN class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv3dNN(object):\n",
    "    def __init__(self, n_classes=2, batchsize=50,\n",
    "                 epochs=10, learning_rate=1e-4, \n",
    "                 dropout_rate=0.5,\n",
    "                 shuffle=True, random_seed=None):\n",
    "        np.random.seed(random_seed)\n",
    "        self.batchsize = batchsize\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.shuffle = shuffle\n",
    "        self.n_classes = n_classes\n",
    "                \n",
    "        g = tf.Graph()\n",
    "        with g.as_default():\n",
    "            ## set random-seed:\n",
    "            tf.set_random_seed(random_seed)\n",
    "            \n",
    "            ## build the network:\n",
    "            self.build()\n",
    "\n",
    "            ## initializer\n",
    "            self.init_op = \\\n",
    "                tf.global_variables_initializer()\n",
    "\n",
    "            ## saver\n",
    "            self.saver = tf.train.Saver()\n",
    "            \n",
    "        ## create a session\n",
    "        self.sess = tf.Session(graph=g)\n",
    "                \n",
    "    def build(self):\n",
    "        \n",
    "        ## Placeholders for X and y:\n",
    "        tf_x = tf.placeholder(tf.float32, \n",
    "                              shape=[None, 79, 95, 79],\n",
    "                              name='tf_x')\n",
    "        tf_y = tf.placeholder(tf.int32, \n",
    "                              shape=[None],\n",
    "                              name='tf_y')\n",
    "        is_train = tf.placeholder(tf.bool, \n",
    "                              shape=(),\n",
    "                              name='is_train')\n",
    "        \n",
    "        ## reshape x to 5D tensor:\n",
    "        ## [batchsize, x, y, z, 1]\n",
    "        tf_x_vol = tf.reshape(tf_x, shape=[-1, 79, 95, 79, 1],\n",
    "                             name='input_x_3d_volumes')\n",
    "\n",
    "        ## One-hot encoding:\n",
    "        tf_y_onehot = tf.one_hot(indices=tf_y, depth=2,\n",
    "                              dtype=tf.float32,\n",
    "                              name='input_y_onehot')\n",
    "\n",
    "        ## 1st layer: Conv_1\n",
    "        h1 = tf.layers.conv3d(tf_x_vol, \n",
    "                              filters=8, \n",
    "                              kernel_size=(7, 7, 7), \n",
    "                              strides=(1, 1, 1),\n",
    "                              padding='valid',\n",
    "                              activation=tf.nn.relu)\n",
    "        ## MaxPooling\n",
    "        h1_pool = tf.layers.max_pooling3d(h1, \n",
    "                              pool_size=(2, 2, 2), \n",
    "                              strides=(2, 2, 2))\n",
    "        \n",
    "        ## 2nd layer: Conv_2\n",
    "        h2 = tf.layers.conv3d(h1_pool, \n",
    "                              filters=16, \n",
    "                              kernel_size=(5, 5, 5), \n",
    "                              strides=(1,1,1),\n",
    "                              padding='valid',\n",
    "                              activation=tf.nn.relu)\n",
    "        ## MaxPooling \n",
    "        h2_pool = tf.layers.max_pooling3d(h2, \n",
    "                              pool_size=(2, 2, 2), \n",
    "                              strides=(2, 2, 2))\n",
    "\n",
    "        ## 3rd layer: Conv_3\n",
    "        h3 = tf.layers.conv3d(h2_pool, \n",
    "                              filters=32, \n",
    "                              kernel_size=(3, 3, 3), \n",
    "                              strides=(1,1,1),\n",
    "                              padding='valid',\n",
    "                              activation=tf.nn.relu)\n",
    "        ## MaxPooling \n",
    "        h3_pool = tf.layers.max_pooling3d(h3, \n",
    "                              pool_size=(2, 2, 2), \n",
    "                              strides=(2, 2, 2))\n",
    "        \n",
    "        ## 4th layer: Fully Connected\n",
    "        input_shape = h3_pool.get_shape().as_list()\n",
    "        n_input_units = np.prod(input_shape[1:])\n",
    "        h3_pool_flat = tf.reshape(h3_pool, \n",
    "                              shape=[-1, n_input_units])\n",
    "        \n",
    "        h4 = tf.layers.dense(h3_pool_flat, 128, \n",
    "                              activation=tf.nn.relu)\n",
    "\n",
    "        ## Dropout\n",
    "        h4_drop = tf.layers.dropout(h4, \n",
    "                              rate=self.dropout_rate,\n",
    "                              training=is_train)\n",
    "        \n",
    "        ## 5th layer: Fully Connected (linear activation)\n",
    "        h5 = tf.layers.dense(h4_drop, self.n_classes, \n",
    "                              activation=tf.nn.sigmoid)\n",
    "\n",
    "        ## Prediction\n",
    "        predictions = {\n",
    "            'probabilities': tf.nn.softmax(h5, \n",
    "                              name='probabilities'),\n",
    "            'labels': tf.cast(tf.argmax(h5, axis=1), \n",
    "                              tf.int32, name='labels')}\n",
    "        \n",
    "        ## Loss Function and Optimization\n",
    "        cross_entropy_loss = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(\n",
    "                logits=h5, labels=tf_y_onehot),\n",
    "            name='cross_entropy_loss')\n",
    "        \n",
    "        ## Optimizer:\n",
    "        optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        optimizer = optimizer.minimize(cross_entropy_loss,\n",
    "                              name='train_op')\n",
    "\n",
    "        ## Finding accuracy\n",
    "        correct_predictions = tf.equal(\n",
    "            predictions['labels'], \n",
    "            tf_y, name='correct_preds')\n",
    "        \n",
    "        accuracy = tf.reduce_mean(\n",
    "            tf.cast(correct_predictions, tf.float32),\n",
    "            name='accuracy')\n",
    "\n",
    "    def save(self, epoch, path='./CNN3d-tflayers-modeltest/'):\n",
    "        if not os.path.isdir(path):\n",
    "            os.makedirs(path)\n",
    "        print('Saving model in %s' % path)\n",
    "        self.saver.save(self.sess, \n",
    "                        os.path.join(path, 'zero_model_10.ckpt'),\n",
    "                        global_step=epoch)\n",
    "        \n",
    "    def load(self, epoch, path):\n",
    "        print('Loading model from %s' % path)\n",
    "        self.saver.restore(self.sess, \n",
    "             os.path.join(path, 'zero_model_10.ckpt-%d' % epoch))\n",
    "        \n",
    "    def train(self, training_set, \n",
    "              validation_set=None,\n",
    "              initialize=True):\n",
    "        ## initialize variables\n",
    "        if initialize:\n",
    "            self.sess.run(self.init_op)\n",
    "\n",
    "        self.train_cost_ = []\n",
    "\n",
    "        for epoch in range(1, self.epochs + 1):      avg_loss = 0.0\n",
    "            for batch_x,batch_y in batch_generator(np.array(training_set[0]),np.array(training_set[1]), batch_size=self.batchsize,shuffle=self.shuffle):\n",
    "               \n",
    "                feed = {'tf_x:0': batch_x, \n",
    "                        'tf_y:0': batch_y,\n",
    "                        'is_train:0': True} ## for dropout\n",
    "                loss, _ = self.sess.run(\n",
    "                        ['cross_entropy_loss:0', 'train_op'], \n",
    "                        feed_dict=feed)\n",
    "                avg_loss += loss\n",
    "                \n",
    "            print('Epoch %02d: Training Avg. Loss: '\n",
    "                  '%7.3f' % (epoch, avg_loss), end=' ')\n",
    "            if validation_set is not None:\n",
    "                \n",
    "                X_data_ts = np.array(training_set[0])\n",
    "                y_data_ts = np.array(training_set[1])\n",
    "                # test accuracy\n",
    "                batch_gen_ts = \\\n",
    "                batch_generator(X_data_ts, y_data_ts,\n",
    "                                 shuffle=False,batch_size=self.batchsize)\n",
    "                avg_valid_acc = 0.0\n",
    "                for i, (batch_x,batch_y) in \\\n",
    "                    enumerate(batch_gen_ts):\n",
    "                    feed = {'tf_x:0': batch_x,\n",
    "                            'tf_y:0': batch_y,\n",
    "                            'is_train:0': False} ## for dropout\n",
    "                    avg_valid_acc = avg_valid_acc + self.sess.run('accuracy:0', feed_dict=feed)\n",
    "                avg_valid_acc = avg_valid_acc/(i+1)\n",
    "                \n",
    "                print('Validation Acc: %7.3f' % avg_valid_acc)\n",
    "            else:\n",
    "                print()\n",
    "                    \n",
    "    def predict(self, X_test, return_proba = False):\n",
    "        feed = {'tf_x:0': X_test,\n",
    "                'is_train:0': False} ## for dropout\n",
    "        if return_proba:\n",
    "            return self.sess.run('probabilities:0',\n",
    "                                 feed_dict=feed)\n",
    "        else:\n",
    "            return self.sess.run('labels:0',\n",
    "                                 feed_dict=feed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an instance of the CNN3dNN class, train it, and save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(len(X_tr_centered)/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hterborg/.local/lib/python3.7/site-packages/tensorflow/python/keras/legacy_tf_layers/convolutional.py:628: UserWarning: `tf.layers.conv3d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv3D` instead.\n",
      "  warnings.warn('`tf.layers.conv3d` is deprecated and '\n",
      "/home/hterborg/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "/home/hterborg/.local/lib/python3.7/site-packages/tensorflow/python/keras/legacy_tf_layers/pooling.py:464: UserWarning: `tf.layers.max_pooling3d` is deprecated and will be removed in a future version. Please use `tf.keras.layers.MaxPooling3D` instead.\n",
      "  warnings.warn('`tf.layers.max_pooling3d` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hterborg/.local/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hterborg/.local/lib/python3.7/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  warnings.warn('`tf.layers.dense` is deprecated and '\n",
      "/home/hterborg/.local/lib/python3.7/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:268: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
      "  warnings.warn('`tf.layers.dropout` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Training Avg. Loss:  58.280 Validation Acc:   0.667\n",
      "Epoch 02: Training Avg. Loss:  53.499 Validation Acc:   0.679\n",
      "Epoch 03: Training Avg. Loss:  52.977 Validation Acc:   0.674\n",
      "Epoch 04: Training Avg. Loss:  53.606 Validation Acc:   0.697\n",
      "Epoch 05: Training Avg. Loss:  52.923 Validation Acc:   0.690\n",
      "Epoch 06: Training Avg. Loss:  52.700 Validation Acc:   0.721\n",
      "Epoch 07: Training Avg. Loss:  52.449 Validation Acc:   0.737\n",
      "Epoch 08: Training Avg. Loss:  52.224 Validation Acc:   0.740\n",
      "Epoch 09: Training Avg. Loss:  51.555 Validation Acc:   0.736\n",
      "Epoch 10: Training Avg. Loss:  51.262 Validation Acc:   0.770\n",
      "Saving model in ./CNN3d-tflayers-modeltest/\n"
     ]
    }
   ],
   "source": [
    "cnn3d = Conv3dNN( random_seed=123,epochs=10, n_classes=n_classes)\n",
    "\n",
    "cnn3d.train(training_set=(X_tr_centered, y_train), \n",
    "         validation_set=(X_ts_centered, y_test))\n",
    "\n",
    "cnn3d.save(epoch=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-24-a99e12e87171>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-a99e12e87171>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    validation_set=(X_ts_centered, y_test),initialize=False)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#cnn3d_re.train(training_set=(X_tr_centered, y_train), \n",
    "         validation_set=(X_ts_centered, y_test),initialize=False)\n",
    "#[0:round((len(X_tr_centered)/4))]\n",
    "#cnn3d.save(epoch=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To load the trained model and to test it using data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ./CNN3d-tflayers-modeltest/\n",
      "INFO:tensorflow:Restoring parameters from ./CNN3d-tflayers-modeltest/zero_model_10.ckpt-10\n",
      "[1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#del cnn3d\n",
    "\n",
    "cnn3d_re = Conv3dNN(random_seed=123)\n",
    "cnn3d_re.load(epoch=10, path='./CNN3d-tflayers-modeltest/')\n",
    "\n",
    "print(cnn3d_re.predict(X_ts_centered[:10,:,:,:]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuray for all test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ts_centered2 = X_ts_centered[100:300,:,:,:]\n",
    "y_test2 =y_test[100:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 77.85\n"
     ]
    }
   ],
   "source": [
    "preds = cnn3d_re.predict(X_ts_centered)\n",
    "\n",
    "print('Test Accuracy: {:.2f}'.format( 100 * np.sum(y_test == preds)/len(y_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff:  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0 -1 -1  0 -1 -1 -1 -1 -1 -1  0 -1  0  0 -1 -1 -1 -1 -1\n",
      "  0  0  0  0  0  0  0  0 -1  0 -1 -1  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  1  1  0  0  1  1  0  1  0  0  0  0  0  0  0  0  1\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0 -1 -1 -1 -1  0  0\n",
      "  0  0  0  0  0 -1 -1 -1  0  0 -1 -1 -1  0  0  0  0 -1 -1  0  0  0 -1  0\n",
      "  0  0  0  0  0  0  0  0  0  1  1  0  0  0  0  0  1  0  0  0  0  0  1  1\n",
      "  0  0  1  1  0  0  0  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1 -1 -1  0 -1  0\n",
      "  0 -1  0  0  0 -1 -1  0  0 -1 -1 -1 -1  0  0 -1  0 -1 -1 -1 -1  0  0  0\n",
      "  0  0  0 -1  0  0  0  0  0  0  0  1  0  0  0  0  0  1  0  1  0  0  0  0\n",
      "  0  0  0  0  0  0  0  1  0  0  1  0  0  0  1  1  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0]\n",
      "Correctly classified:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  32  39  41  42  48  49\n",
      "  50  51  52  53  54  55  57  60  61  62  63  64  65  66  67  68  69  70\n",
      "  71  72  73  74  75  76  77  78  81  82  85  87  88  89  90  91  92  93\n",
      "  94  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112\n",
      " 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130\n",
      " 131 132 133 134 135 137 142 143 144 145 146 147 148 152 153 157 158 159\n",
      " 160 163 164 165 167 168 169 170 171 172 173 174 175 176 179 180 181 182\n",
      " 183 185 186 187 188 189 192 193 196 197 198 199 200 203 204 205 206 207\n",
      " 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225\n",
      " 226 227 228 229 230 231 232 233 237 239 240 242 243 244 247 248 253 254\n",
      " 256 261 262 263 264 265 266 268 269 270 271 272 273 274 276 277 278 279\n",
      " 280 282 284 285 286 287 288 289 290 291 292 293 294 296 297 299 300 301\n",
      " 304 305 306 307 308 309 310 311 312 313 314 315]\n",
      "Incorrectly classified:  [ 30  31  33  34  35  36  37  38  40  43  44  45  46  47  56  58  59  79\n",
      "  80  83  84  86  95 136 138 139 140 141 149 150 151 154 155 156 161 162\n",
      " 166 177 178 184 190 191 194 195 201 202 234 235 236 238 241 245 246 249\n",
      " 250 251 252 255 257 258 259 260 267 275 281 283 295 298 302 303]\n",
      "False positives:  [ 30  31  33  34  35  36  37  38  40  43  44  45  46  47  56  58  59 136\n",
      " 138 139 140 141 149 150 151 154 155 156 161 162 166 234 235 236 238 241\n",
      " 245 246 249 250 251 252 255 257 258 259 260 267]\n",
      "False negatives:  [ 79  80  83  84  86  95 177 178 184 190 191 194 195 201 202 275 281 283\n",
      " 295 298 302 303]\n"
     ]
    }
   ],
   "source": [
    "diff = y_test-preds\n",
    "print('diff: ',diff)\n",
    "\n",
    "# Correct is 0 \n",
    "# FP is -1 \n",
    "# FN is 1\n",
    "print('Correctly classified: ', np.where(diff == 0)[0])\n",
    "print('Incorrectly classified: ', np.where(diff != 0)[0])\n",
    "print('False positives: ', np.where(diff == -1)[0])\n",
    "print('False negatives: ', np.where(diff == 1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.size(np.where(diff == -1)) #false positive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.size(np.where(diff == 1)) # false negative"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
